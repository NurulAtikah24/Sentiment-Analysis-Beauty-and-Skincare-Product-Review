# -*- coding: utf-8 -*-
"""(Final)Sentiment Analysis Beauty & Skincare Product Reviews.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12nRasKm2ovSObLRP5uF4jwREwAAZNT9r

# DATA COLLECTION
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re
import nltk
import string

from matplotlib import style
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from nltk.stem import PorterStemmer
from nltk.corpus import stopwords
from nltk.sentiment import SentimentIntensityAnalyzer
from wordcloud import WordCloud
from textblob import TextBlob
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

nltk.download('punkt')
nltk.download('wordnet')
nltk.download('stopwords')
nltk.download('vader_lexicon')

pip install nltk

"""load the dataset directly from githuub and preview the dataframe."""

# Importing necessary libraries
import pandas as pd

# GitHub raw content link for the CSV file
url = "https://raw.githubusercontent.com/nadyinky/sephora-analysis/main/datasets/skincare_products_reviews.csv"

# Loading in products data
df = pd.read_csv(url)
df.info(verbose=True)

"""From this, we gather that the products dataset contains 19 columns and 49977 rows of data. The columns vary in data types, and there is missing data within the dataframe."""

with pd.option_context('display.max_colwidth', 20, 'display.max_columns', None):
    display(df.head())

print(df.columns)

df.shape

# Define the columns to keep
columns_to_keep = ['review_text', 'rating', 'product_name', 'brand_name']

# Drop all columns except for 'review_text' and 'rating'
df.drop(columns=df.columns.difference(columns_to_keep), inplace=True)

# Display the resulting DataFrame
df.head()

"""Since further analysis will focus on the text of the review and the customer rating, I will leave only the `'rating'` and `'review_text'` columns and rename them for simplicity. I will also check how many reviews have only a rating and have no review text"""

# Check number of rows where there is no review
df.isnull().sum()

# Drop all rows where there is no review
df = df.dropna(subset=['review_text'])
df.isnull().sum()

# Save the review DataFrame to a CSV file
df[['review_text', 'product_name', 'brand_name']].to_csv("productreview.csv", index=False)

"""# PRE-PROCESSING PHASE"""

def clean_text(text: str) -> str:
    """Cleans input text, tokenizes, removes stop words, and lemmatizes it"""

    # Remove emojis
    text = text.encode('ascii', 'ignore').decode('ascii')

    # Remove digits, non-word/space characters, and consecutive repeating characters
    text = re.sub(r'\d+|[^\w\s]|\b(\w+)(\s+\1)+\b', '', text)

    # Remove punctuation and convert to lowercase
    text = text.translate(str.maketrans('', '', string.punctuation)).lower()

    # Tokenize, remove stop words, and lemmatize
    stop_words = set(stopwords.words('english'))
    lemmatizer = WordNetLemmatizer()
    tokens = []
    for w in word_tokenize(text):
        lemma = lemmatizer.lemmatize(w)
        if w.endswith('ed') or w.endswith('ing'):
            # Lemmatize words ending with 'ed' or 'ing' as verbs
            lemma = lemmatizer.lemmatize(w, pos='v')
        if lemma not in stop_words and len(lemma) > 2:
            tokens.append(lemma)

    # Join tokens back into a single string
    text = ' '.join(tokens)

    return text

# Apply the new function and create a column with lemmatized text
df['clean_text'] = df['review_text'].apply(clean_text)

# Create a column with a set of tokenized review words
df['NLTK_text'] = df['clean_text'].apply(lambda x: nltk.Text(nltk.word_tokenize(x)))

from tabulate import tabulate

# Display the original and cleaned reviews side by side in a table
table = [["Original Review", df['review_text'][1]],
         ["Cleaned Review", df['clean_text'][1]]]

print(tabulate(table, headers=["Review Type", "Text"], tablefmt="grid"))

"""I added the cleaned reviews as a new column `'clean_text'`, and added another one `'NLTK_text'` that contains each review as a sequence of words (tokens) in the `nltk.text.Text` wrapper."""

# Print only selected columns
selected_columns = ['review_text', 'clean_text', 'NLTK_text']
df[selected_columns].head(5)

#Shape of the dataset, and breakdown of the classes
print(f"Input data has {len(df)} rows and {len(df.columns)} columns")
print(f"rating 1 = {len(df[df['rating']==1])} rows")
print(f"rating 2 = {len(df[df['rating']==2])} rows")
print(f"rating 3 = {len(df[df['rating']==3])} rows")
print(f"rating 4 = {len(df[df['rating']==4])} rows")
print(f"rating 5 = {len(df[df['rating']==5])} rows")

sns.set_style('whitegrid')
sns.countplot(data=df, x='rating', palette='flare').set_title('Rating Distribution Across Dataset')
sns.despine()

# Save the cleaned DataFrame to a CSV file
df[['review_text', 'clean_text', 'NLTK_text']].to_csv("cleaneddata.csv", index=False)

"""# CLASSIFICATION PHASE"""

import nltk
import pandas as pd
from nltk.sentiment.vader import SentimentIntensityAnalyzer

# Download the VADER lexicon (run once)
nltk.download('vader_lexicon')

# Initialize the VADER sentiment analyzer
sid = SentimentIntensityAnalyzer()

# Define a function to categorize reviews and return sentiment score
def categorize_review(text):
    # Compute sentiment scores
    scores = sid.polarity_scores(text)
    sentiment_score = scores['compound']

    # Determine sentiment category based on compound score
    if sentiment_score > 0.1:
        sentiment_category = 'positif'
    elif sentiment_score < -0.1:
        sentiment_category = 'negatif'
    else:
        sentiment_category = 'neutral'

    return sentiment_score, sentiment_category

# Apply the function to categorize reviews and extract sentiment score
df['sentiment_score'], df['sentiment'] = zip(*df['review_text'].apply(categorize_review))

# Print all columns except the 'rating' column
columns_to_print = [col for col in df.columns if col != 'rating']
df[columns_to_print]

# Save the cleaned DataFrame to a CSV file
df[['review_text', 'product_name', 'brand_name', 'sentiment_score', 'sentiment']].to_csv("sentimentdatatwo.csv", index=False)

import nltk
import pandas as pd
from nltk.sentiment.vader import SentimentIntensityAnalyzer

# Download the VADER lexicon (run once)
nltk.download('vader_lexicon')

# Initialize the VADER sentiment analyzer
sid = SentimentIntensityAnalyzer()

# Define a function to categorize reviews and return sentiment score
def categorize_review(text):
    # Compute sentiment scores
    scores = sid.polarity_scores(text)
    sentiment_score = scores['compound']

    # Determine sentiment category based on compound score
    if sentiment_score > 0.05:
        sentiment_category = 'positif'
    elif sentiment_score < -0.05:
        sentiment_category = 'negatif'
    else:
        sentiment_category = 'neutral'

    return sentiment_score, sentiment_category

# Apply the function to categorize reviews and extract sentiment score
df['sentiment_score'], df['sentiment'] = zip(*df['review_text'].apply(categorize_review))

# Print all columns except the 'rating' column
columns_to_print = [col for col in df.columns if col != 'rating']
df[columns_to_print]

df.info()

# Save the cleaned DataFrame to a CSV file
df[['review_text', 'product_name', 'brand_name', 'sentiment_score', 'sentiment']].to_csv("sentimentdata.csv", index=False)

# Group by product_name, brand_name, and sentiment, then count occurrences
sentiment_counts = df.groupby(['product_name', 'brand_name', 'sentiment']).size().unstack(fill_value=0)

# Calculate total of positive, negative, neutral sentiments for every product and brand
sentiment_counts['total_positive'] = sentiment_counts['positif']
sentiment_counts['total_negative'] = sentiment_counts['negatif']
sentiment_counts['total_neutral'] = sentiment_counts['neutral']

# Drop individual sentiment columns as they are not needed anymore
sentiment_counts.drop(columns=['positif', 'negatif', 'neutral'], inplace=True)

sentiment_counts

# Apply the function to categorize reviews and extract sentiment score and sentiment
df['sentiment_score'], df['sentiment'] = zip(*df['review_text'].apply(categorize_review))

# Group by product_name, brand_name, and sentiment, then count occurrences
sentiment_counts = df.groupby(['product_name', 'brand_name', 'sentiment']).size().unstack(fill_value=0)

# Ensure all sentiment types are present in the DataFrame
for sentiment in ['positif', 'negatif', 'neutral']:
    if sentiment not in sentiment_counts.columns:
        sentiment_counts[sentiment] = 0

# Reorder columns to maintain consistency
sentiment_counts = sentiment_counts[['positif', 'negatif', 'neutral']]

# Calculate total of positive, negative, neutral sentiments for every product and brand
sentiment_counts['total_positive'] = sentiment_counts['positif']
sentiment_counts['total_negative'] = sentiment_counts['negatif']
sentiment_counts['total_neutral'] = sentiment_counts['neutral']

# Drop individual sentiment columns as they are not needed anymore
sentiment_counts.drop(columns=['positif', 'negatif', 'neutral'], inplace=True)

# Sort the DataFrame by total_positive in descending order
sentiment_counts_sorted = sentiment_counts.sort_values(by='total_positive', ascending=False)

# Select the top 10 brands with the most positive sentiment
top_10_brands = sentiment_counts_sorted.head(10)

# Save the output to a CSV file
output_file_path = "top_10_brands_sentiment_summary.csv"
top_10_brands.to_csv(output_file_path)

print(f"Top 10 brands with the most positive sentiments have been saved to {output_file_path}")

# Display the top 10 brands
top_10_brands

# Define data and labels
data = df['sentiment'].value_counts()
labels = df['sentiment'].unique()

# Create pie chart
plt.figure(figsize=(6, 6))
plt.pie(data, labels=labels, colors=['#00CD66', '#FF0000', '#FFFF00'], autopct='%.0f%%')
plt.title('Sentiment Distribution of Beauty and Skincare Product Reviews', fontsize=14);

# Define data and labels
data = df['sentiment'].value_counts()
labels = df['sentiment'].unique()

# Plot Histogram
plt.subplot(1, 2, 2)
df['sentiment'].value_counts().plot(kind='bar', color=['#00CD66', '#FF0000', '#FFFF00'])
plt.title('Sentiment Distribution of Beauty and Skincare Product Reviews', fontsize=14)
plt.xlabel('Sentiment')
plt.ylabel('Count')

# Define data and labels
data = df['sentiment'].value_counts()
labels = df['sentiment'].unique()

# Print the data
print("Sentiment Distribution:")
for label, count in zip(labels, data):
    print(f"{label}: {count} rows")

"""# FEATURE EXTRACTION"""

# Original dataframe size
df.shape

from sklearn.feature_extraction.text import TfidfVectorizer
# Separate features (X) and target (y)
X = df['clean_text']
y = df['sentiment']

# Create an instance of TfidfVectorizer
tfidf_vectorizer = TfidfVectorizer()

# Fit and transform the text data
X = tfidf_vectorizer.fit_transform(X)

# Apply train-test split to maintain a balanced ratio of classes in both train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Get a smaller representative sample of data
sample_size = 10000
df_sample = (df[['clean_text', 'sentiment']]
                .groupby('sentiment')
                .apply(lambda x: x.sample(n=sample_size, replace=True))
                .reset_index(drop=True))

# Use TFID vectorizer and split data into training and test sets
tfidf = TfidfVectorizer(ngram_range=(1, 3), max_features=5000)
X = tfidf.fit_transform(df_sample['clean_text'])
y = df_sample['sentiment']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state=42)

# Show new sample and train/test set sizes
print('New sample full size:', df_sample.shape)
print('The shape of X_train:', X_train.shape)
print('The shape of X_test:', X_test.shape)
print('The shape of y_train:', y_train.shape)
print('The shape of y_test:', y_test.shape)

from collections import Counter
import matplotlib.pyplot as plt
import seaborn as sns

# Count word frequencies
top_words = Counter(' '.join(df['clean_text']).split()).most_common(20)

# Convert the list of tuples into a pandas DataFrame
top_words_df = pd.DataFrame(top_words, columns=['word', 'count'])

# Create a custom color palette
colors = sns.color_palette('husl', len(top_words_df))

# Create a horizontal bar chart using Seaborn's barplot function
plt.figure(figsize=(7, 7))
sns.set(style="whitegrid")
sns.barplot(x="count", y="word", data=top_words_df, palette=colors)

# Add a title to the chart
plt.title('Top Frequent Words', fontsize=14, y=1.03)
plt.show()

from sklearn.feature_extraction.text import TfidfVectorizer

# Create a TF-IDF vectorizer
tfidf_vectorizer = TfidfVectorizer(max_features=5000)

# Fit and transform the 'review_text' column
tfidf_matrix = tfidf_vectorizer.fit_transform(df['clean_text'])

# Convert the TF-IDF matrix to a DataFrame
tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())

# Display the frequency of words
word_frequencies = tfidf_df.sum().sort_values(ascending=False)
print("\nWord Frequencies:")
print(word_frequencies.head(20))  # Display the top 20 words by frequency

# Visualization of the frequency of words with multiple colors
colors = ['skyblue', 'lightgreen', 'coral', 'lightblue', 'salmon', 'lightcoral', 'lightpink', 'palegreen', 'cadetblue', 'thistle']
plt.figure(figsize=(12, 6))
word_frequencies.head(20).plot(kind='bar', color=colors)
plt.title('Top 20 Words by Frequency in TF-IDF Matrix')
plt.xlabel('Words')
plt.ylabel('Frequency')
plt.show()

top_words = Counter(' '.join(df['clean_text']).split())

# Create a word cloud
wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(dict(top_words))

# Plot the word cloud
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off');

"""# HANDLING UNBALANCED DATA USING SMOTE

**Before SMOTE:** The model might be biased towards the majority class because it has more samples to learn from.

**After SMote:** The model gets more balanced data, which helps it to learn more about the minority class. This can lead to better overall performance metrics, especially on the minority class.
"""

!pip install imbalanced-learn

from imblearn.over_sampling import SMOTE
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

from collections import Counter

# Count the number of instances for each class in the oversampled data
class_distribution = Counter(y_train_smote)

# Print the class distribution
print(class_distribution)

# Pie chart, where the slices will be ordered and plotted counter-clockwise:
labels = class_distribution.keys()
sizes = class_distribution.values()

# Explode out the first slice (optional)
explode = (0.1,) * len(class_distribution)  # only "explode" the 1st slice if there are multiple classes

# Plot
plt.figure(figsize=(5, 5))
plt.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', colors=['#00CD66', '#FF0000', '#FFFF00'])
plt.title('Balanced Sentiment Distribution after Applying SMOTE')
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.show()

print('The shape of X_train_smote:', X_train_smote.shape)
print('The shape of y_train_smote:', y_train_smote.shape)

"""# PREDICTION MODEL BEFORE SMOTE"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

# Initialize and train Decision Tree Classifier
decision_tree_classifier = DecisionTreeClassifier()
decision_tree_classifier.fit(X_train, y_train)

# Predict and evaluate on test set
decision_tree_predict = decision_tree_classifier.predict(X_test)
decision_tree_accuracy_bfr = accuracy_score(decision_tree_predict, y_test)

# Print the test accuracy
print("Decision Tree Classifier Accuracy:", decision_tree_accuracy_bfr)

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Initialize and train Random Forest Classifier
random_forest_classifier = RandomForestClassifier()
random_forest_classifier.fit(X_train, y_train)

# Predict and evaluate on test set
random_forest_predict = random_forest_classifier.predict(X_test)
random_forest_accuracy_bfr = accuracy_score(random_forest_predict, y_test)

# Print the accuracy
print("Random Forest Classifier Accuracy:", random_forest_accuracy_bfr)

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# Initialize and train Support Vector Classifier
svc_classifier = SVC()
svc_classifier.fit(X_train, y_train)

# Predict and evaluate on test set
svc_predict = svc_classifier.predict(X_test)
svc_accuracy_bfr = accuracy_score(svc_predict, y_test)

# Print the test accuracy
print("Support Vector Machine Accuracy:", svc_accuracy_bfr)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Initialize and train Logistic Regression Classifier
logistic_regression_classifier = LogisticRegression(max_iter=1000)
logistic_regression_classifier.fit(X_train, y_train)

# Predict and evaluate on test set
logistic_regression_predict = logistic_regression_classifier.predict(X_test)
logistic_regression_accuracy_bfr = accuracy_score(logistic_regression_predict, y_test)

# Print the accuracy
print("Logistic Regression Classifier Accuracy:", logistic_regression_accuracy_bfr)

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# Initialize and train K-Nearest Neighbors Classifier
kneighbors_classifier = KNeighborsClassifier()
kneighbors_classifier.fit(X_train, y_train)

# Predict and evaluate on test set
kneighbors_predict = kneighbors_classifier.predict(X_test)
kneighbors_accuracy_bfr = accuracy_score(kneighbors_predict, y_test)

# Print the accuracy
print("K-Nearest Neighbors Classifier Accuracy:", kneighbors_accuracy_bfr)

from sklearn.naive_bayes import BernoulliNB
from sklearn.metrics import accuracy_score

# Initialize and train Naive Bayes Classifier
bernoulli_nb_classifier = BernoulliNB()
bernoulli_nb_classifier.fit(X_train, y_train)

# Predict and evaluate on test set
bernoulli_nb_predict = bernoulli_nb_classifier.predict(X_test)
bernoulli_nb_accuracy_bfr = accuracy_score(bernoulli_nb_predict, y_test)

# Print the accuracy
print("Naive Bayes Classifier Accuracy:", bernoulli_nb_accuracy_bfr)

"""# PREDICTION MODEL AFTER SMOTE"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

# Initialize and train Decision Tree Classifier
decision_tree_classifier = DecisionTreeClassifier()
decision_tree_classifier.fit(X_train_smote, y_train_smote)

# Predict and evaluate on test set
decision_tree_predict = decision_tree_classifier.predict(X_test)
decision_tree_accuracy_aft = accuracy_score(decision_tree_predict, y_test)

# Print the test accuracy
print("Decision Tree Classifier Accuracy:", decision_tree_accuracy_aft)

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Initialize and train Random Forest Classifier
random_forest_classifier = RandomForestClassifier()
random_forest_classifier.fit(X_train_smote, y_train_smote)

# Predict and evaluate on test set
random_forest_predict = random_forest_classifier.predict(X_test)
random_forest_accuracy_aft = accuracy_score(random_forest_predict, y_test)

# Print the accuracy
print("Random Forest Classifier Accuracy (with SMOTE):", random_forest_accuracy_aft)

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# Initialize and train Support Vector Classifier
svc_classifier = SVC()
svc_classifier.fit(X_train_smote, y_train_smote)

# Predict and evaluate on test set
svc_predict = svc_classifier.predict(X_test)
svc_accuracy_aft = accuracy_score(svc_predict, y_test)

# Print the accuracy
print("Support Vector Machine Accuracy (with SMOTE):", svc_accuracy_aft)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Initialize and train Logistic Regression Classifier
logistic_regression_classifier = LogisticRegression(max_iter=1000)
logistic_regression_classifier.fit(X_train_smote, y_train_smote)

# Predict and evaluate on test set
logistic_regression_predict = logistic_regression_classifier.predict(X_test)
logistic_regression_accuracy_aft = accuracy_score(logistic_regression_predict, y_test)

# Print the accuracy
print("Logistic Regression Classifier Accuracy (with SMOTE):", logistic_regression_accuracy_aft)

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# Initialize and train K-Nearest Neighbors Classifier
kneighbors_classifier = KNeighborsClassifier()
kneighbors_classifier.fit(X_train_smote, y_train_smote)

# Predict and evaluate on test set
kneighbors_predict = kneighbors_classifier.predict(X_test)
kneighbors_accuracy_aft = accuracy_score(kneighbors_predict, y_test)

# Print the accuracy
print("K-Nearest Neighbors Classifier Accuracy (with SMOTE):", kneighbors_accuracy_aft)

from sklearn.naive_bayes import BernoulliNB
from sklearn.metrics import accuracy_score

# Initialize and train Naive Bayes Classifier
bernoulli_nb_classifier = BernoulliNB()
bernoulli_nb_classifier.fit(X_train_smote, y_train_smote)

# Predict and evaluate on test set
bernoulli_nb_predict = bernoulli_nb_classifier.predict(X_test)
bernoulli_nb_accuracy_aft = accuracy_score(bernoulli_nb_predict, y_test)

# Print the accuracy
print("Naive Bayes Classifier Accuracy (with SMOTE):", bernoulli_nb_accuracy_aft)

"""# EVALUATION MODEL BEFORE SMOTE"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, confusion_matrix

# Train the DecisionTreeClassifier model on the subset
dt_classifier_bfr = DecisionTreeClassifier(random_state=42)
dt_classifier_bfr.fit(X_train, y_train)

# Make predictions on the test set
dt_pred_bfr = dt_classifier_bfr.predict(X_test)

# Print classification report
print('Classification report:\n', classification_report(y_test, dt_pred_bfr, digits=4))

# Create heatmap
cm = confusion_matrix(y_test, dt_pred_bfr)
sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=labels, yticklabels=labels)
plt.xlabel('Predicted Sentiment')
plt.ylabel('True Sentiment')
plt.title('Confusion Matrix for Decision Tree Classifier')
plt.show()

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

# Train the RandomForestClassifier model on the subset
rf_classifier_bfr = RandomForestClassifier(n_estimators=100, random_state=42)
rf_classifier_bfr.fit(X_train, y_train)

# Make predictions on the test set
rf_pred_bfr = rf_classifier_bfr.predict(X_test)

# Print classification report
print('Classification report:\n', classification_report(y_test, rf_pred_bfr, digits=4))

# Create heatmap
cm = confusion_matrix(y_test, rf_pred_bfr)
sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=labels, yticklabels=labels)
plt.xlabel('Predicted Sentiment')
plt.ylabel('True Sentiment')
plt.title('Confusion Matrix for Random Forest Classifier')
plt.show()

from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix

# Train the SVC model on the subset
svc_classifier_bfr = SVC(random_state=42)
svc_classifier_bfr.fit(X_train, y_train)

# Make predictions on the test set
svc_pred_bfr = svc_classifier_bfr.predict(X_test)

# Print classification report
print('Classification report:\n', classification_report(y_test, svc_pred_bfr, digits=4))

# Create heatmap
cm = confusion_matrix(y_test, svc_pred_bfr)
sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=labels, yticklabels=labels)
plt.xlabel('Predicted Sentiment')
plt.ylabel('True Sentiment')
plt.title('Confusion Matrix for Support Vector Machine')
plt.show()

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix

# Train the LogisticRegression model on the subset
lr_classifier_bfr = LogisticRegression(random_state=42, max_iter=1000)
lr_classifier_bfr.fit(X_train, y_train)

# Make predictions on the test set
lr_pred_bfr = lr_classifier_bfr.predict(X_test)

# Print classification report
print('Classification report:\n', classification_report(y_test, lr_pred_bfr, digits=4))

# Create confusion matrix heatmap
cm_lr = confusion_matrix(y_test, lr_pred_bfr)
labels = ['Negative', 'Neutral', 'Positive']
sns.heatmap(cm_lr, annot=True, cmap='Blues', fmt='g', xticklabels=labels, yticklabels=labels)
plt.xlabel('Predicted Sentiment')
plt.ylabel('True Sentiment')
plt.title('Confusion Matrix for Logistic Regression Classifier')
plt.show()

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, confusion_matrix

# Train the KNeighborsClassifier model on the subset
knn_classifier_bfr = KNeighborsClassifier()
knn_classifier_bfr.fit(X_train, y_train)

# Make predictions on the test set
knn_pred_bfr = knn_classifier_bfr.predict(X_test)

# Print classification report
print('Classification report:\n', classification_report(y_test, knn_pred_bfr, digits=4))

# Create confusion matrix heatmap
cm_knn = confusion_matrix(y_test, knn_pred_bfr)
labels = ['Negative', 'Neutral', 'Positive']
sns.heatmap(cm_knn, annot=True, cmap='Blues', fmt='g', xticklabels=labels, yticklabels=labels)
plt.xlabel('Predicted Sentiment')
plt.ylabel('True Sentiment')
plt.title('Confusion Matrix for KNN Classifier')
plt.show()

from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import classification_report, confusion_matrix

# Convert sparse data to dense numpy array
X_train_dense = X_train.toarray()
X_test_dense = X_test.toarray()

# Train the GaussianNB model on the subset
nb_classifier_bfr = GaussianNB()
nb_classifier_bfr.fit(X_train_dense, y_train)

# Make predictions on the test set
nb_pred_bfr = nb_classifier_bfr.predict(X_test_dense)

# Print classification report
print('Classification report:\n', classification_report(y_test, nb_pred_bfr, digits=4))

# Create confusion matrix heatmap
cm_nb = confusion_matrix(y_test, nb_pred_bfr)
labels = ['Negative', 'Neutral', 'Positive']
sns.heatmap(cm_nb, annot=True, cmap='Blues', fmt='g', xticklabels=labels, yticklabels=labels)
plt.xlabel('Predicted Sentiment')
plt.ylabel('True Sentiment')
plt.title('Confusion Matrix for Naive Bayes Classifier')
plt.show()

"""# EVALUATION MODEL AFTER SMOTE"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, confusion_matrix

# Train the DecisionTreeClassifier model
dt_classifier = DecisionTreeClassifier(random_state=42)
dt_classifier.fit(X_train_smote, y_train_smote)

# Make predictions on the test set
dt_pred_aft = dt_classifier.predict(X_test)

# Print classification report
print('Classification report:\n', classification_report(y_test, dt_pred_aft, digits=4))

# Create heatmap for confusion matrix
cm = confusion_matrix(y_test, dt_pred_aft)
sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=labels, yticklabels=labels)
plt.xlabel('Predicted Sentiment')
plt.ylabel('True Sentiment')
plt.title('Confusion Matrix for Decision Tree Classifier')
plt.show()

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

# Train the RandomForestClassifier model
rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
rf_classifier.fit(X_train_smote, y_train_smote)

# Make predictions on the test set
rf_pred_aft = rf_classifier.predict(X_test)

# Print classification report
print('Classification report:\n', classification_report(y_test, rf_pred_aft, digits=4))

# Create heatmap
cm = confusion_matrix(y_test, rf_pred_aft)
sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=labels, yticklabels=labels)
plt.xlabel('Predicted sentiment')
plt.ylabel('True sentiment')
plt.title('Confusion Matrix for Random Forest Classifier');
plt.show()

from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix

# Train the SVC model
svc_classifier = SVC(random_state=42)
svc_classifier.fit(X_train_smote, y_train_smote)

# Make predictions on the test set
svc_pred_aft = svc_classifier.predict(X_test)

# Print classification report
print('Classification report:\n', classification_report(y_test, svc_pred_aft, digits=4))

# Create heatmap
cm = confusion_matrix(y_test, svc_pred_aft)
sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=labels, yticklabels=labels)
plt.xlabel('Predicted Sentiment')
plt.ylabel('True Sentiment')
plt.title('Confusion Matrix for Support Vector Machine');
plt.show()

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix

# Train the LogisticRegression model
lr_classifier = LogisticRegression(random_state=42)
lr_classifier.fit(X_train_smote, y_train_smote)

# Make predictions on the test set
lr_pred_aft = lr_classifier.predict(X_test)

# Print classification report
print('Classification report:\n', classification_report(y_test, lr_pred_aft, digits=4))

# Create confusion matrix heatmap
cm_lr = confusion_matrix(y_test, lr_pred_aft)
labels = ['Negative', 'Neutral', 'Positive']
sns.heatmap(cm_lr, annot=True, cmap='Blues', fmt='g', xticklabels=labels, yticklabels=labels)
plt.xlabel('Predicted sentiment')
plt.ylabel('True sentiment')
plt.title('Confusion Matrix for Logistic Regression Classifier');
plt.show()

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, confusion_matrix

# Train the LogisticRegression model
knn_classifier = KNeighborsClassifier()
knn_classifier.fit(X_train_smote, y_train_smote)

# Make predictions on the test set
knn_pred_aft = knn_classifier.predict(X_test)

# Print classification report
print('Classification report:\n', classification_report(y_test, knn_pred_aft, digits=4))

# Create confusion matrix heatmap
cm_knn = confusion_matrix(y_test, knn_pred_aft)
labels = ['Negative', 'Neutral', 'Positive']
sns.heatmap(cm_knn, annot=True, cmap='Blues', fmt='g', xticklabels=labels, yticklabels=labels)
plt.xlabel('Predicted sentiment')
plt.ylabel('True sentiment')
plt.title('Confusion Matrix for KNN Classifier');
plt.show()

from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import classification_report, confusion_matrix

# Convert sparse data to dense numpy array
X_train_dense = X_train_smote.toarray()
X_test_dense = X_test.toarray()

# Train the LogisticRegression model
nb_classifier = GaussianNB()
nb_classifier.fit(X_train_dense, y_train_smote)

# Make predictions on the test set
nb_pred_aft = nb_classifier.predict(X_test_dense)

# Print classification report
print('Classification report:\n', classification_report(y_test, nb_pred_aft, digits=4))

# Create confusion matrix heatmap
cm_nb = confusion_matrix(y_test, nb_pred_aft)
labels = ['Negative', 'Neutral', 'Positive']
sns.heatmap(cm_nb, annot=True, cmap='Blues', fmt='g', xticklabels=labels, yticklabels=labels)
plt.xlabel('Predicted sentiment')
plt.ylabel('True sentiment')
plt.title('Confusion Matrix for Naive Bayes Classifier');
plt.show()

"""# COMPARISON"""

# Accuracy scores before and after using SMOTE
accuracy_scores_bfr = [decision_tree_accuracy_bfr, random_forest_accuracy_bfr, svc_accuracy_bfr, logistic_regression_accuracy_bfr, kneighbors_accuracy_bfr, bernoulli_nb_accuracy_bfr]
accuracy_scores_aft = [decision_tree_accuracy_aft, random_forest_accuracy_aft, svc_accuracy_aft, logistic_regression_accuracy_aft, kneighbors_accuracy_aft, bernoulli_nb_accuracy_aft]
models = ['Pohon Keputusan', 'Hutan Rawak', 'Mesin Vektor Sokongan', 'Regresi Logistik', 'K-Jiran Terdekat', 'Bayes Naif']

# Plot
plt.figure(figsize=(14, 10))
bar_width = 0.35
index = range(len(models))

# Bars for accuracy scores before SMOTE
bars1 = plt.bar(index, accuracy_scores_bfr, bar_width, color='salmon', label='Sebelum SMOTE')

# Bars for accuracy scores after SMOTE
bars2 = plt.bar([i + bar_width for i in index], accuracy_scores_aft, bar_width, color='lightgreen', label='Selepas SMOTE')

plt.xlabel('Model')
plt.ylabel('Ketepatan')
plt.title('Perbandingan ketepatan antara model')
plt.ylim(0, 1)
plt.xticks([i + bar_width / 2 for i in index], models, rotation=45)

# Add annotations for before SMOTE
for bar, accuracy in zip(bars1, accuracy_scores_bfr):
    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01, f'{accuracy:.4f}', ha='center', va='bottom')

# Add annotations for after SMOTE
for bar, accuracy in zip(bars2, accuracy_scores_aft):
    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01, f'{accuracy:.4f}', ha='center', va='bottom')

plt.legend()
plt.show()

import matplotlib.pyplot as plt
from sklearn.metrics import precision_score

# Assuming you have the predictions before and after SMOTE
# Replace these with your actual prediction variables
# Before SMOTE
dt_pred_bfr = dt_classifier_bfr.predict(X_test)  # Decision Tree
rf_pred_bfr = rf_classifier_bfr.predict(X_test)  # Random Forest
svc_pred_bfr = svc_classifier_bfr.predict(X_test)  # SVM
lr_pred_bfr = lr_classifier_bfr.predict(X_test)  # Logistic Regression
knn_pred_bfr = knn_classifier_bfr.predict(X_test)  # KNN
nb_pred_bfr = nb_classifier_bfr.predict(X_test_dense)  # Naive Bayes

# After SMOTE
dt_pred_aft = dt_classifier.predict(X_test)  # Decision Tree
rf_pred_aft = rf_classifier.predict(X_test)  # Random Forest
svc_pred_aft = svc_classifier.predict(X_test)  # SVM
lr_pred_aft = lr_classifier.predict(X_test)  # Logistic Regression
knn_pred_aft = knn_classifier.predict(X_test)  # KNN
nb_pred_aft = nb_classifier.predict(X_test_dense)  # Naive Bayes

# Calculate precision for each classifier before SMOTE
precision_dt_bfr = precision_score(y_test, dt_pred_bfr, average='weighted')
precision_rf_bfr = precision_score(y_test, rf_pred_bfr, average='weighted')
precision_svc_bfr = precision_score(y_test, svc_pred_bfr, average='weighted')
precision_lr_bfr = precision_score(y_test, lr_pred_bfr, average='weighted')
precision_knn_bfr = precision_score(y_test, knn_pred_bfr, average='weighted')
precision_nb_bfr = precision_score(y_test, nb_pred_bfr, average='weighted')

# Calculate precision for each classifier after SMOTE
precision_dt_aft = precision_score(y_test, dt_pred_aft, average='weighted')
precision_rf_aft = precision_score(y_test, rf_pred_aft, average='weighted')
precision_svc_aft = precision_score(y_test, svc_pred_aft, average='weighted')
precision_lr_aft = precision_score(y_test, lr_pred_aft, average='weighted')
precision_knn_aft = precision_score(y_test, knn_pred_aft, average='weighted')
precision_nb_aft = precision_score(y_test, nb_pred_aft, average='weighted')

# Accuracy scores before and after using SMOTE
precision_scores_bfr = [precision_dt_bfr, precision_rf_bfr, precision_svc_bfr, precision_lr_bfr, precision_knn_bfr, precision_nb_bfr]
precision_scores_aft = [precision_dt_aft, precision_rf_aft, precision_svc_aft, precision_lr_aft, precision_knn_aft, precision_nb_aft]
models = ['Pohon Keputusan', 'Hutan Rawak', 'Mesin Vektor Sokongan', 'Regresi Logistik', 'K-Jiran Terdekat', 'Bayes Naif']

# Plot
plt.figure(figsize=(14, 10))
bar_width = 0.35
index = range(len(models))

# Bars for precision scores before SMOTE
bars1 = plt.bar(index, precision_scores_bfr, bar_width, color='salmon', label='Sebelum SMOTE')

# Bars for precision scores after SMOTE
bars2 = plt.bar([i + bar_width for i in index], precision_scores_aft, bar_width, color='lightgreen', label='Selepas SMOTE')

plt.xlabel('Model')
plt.ylabel('Kejituan')
plt.title('Perbandingan kejituan antara model')
plt.ylim(0, 1)
plt.xticks([i + bar_width / 2 for i in index], models, rotation=45)

# Add annotations for before SMOTE
for bar, precision in zip(bars1, precision_scores_bfr):
    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01, f'{precision:.4f}', ha='center', va='bottom')

# Add annotations for after SMOTE
for bar, precision in zip(bars2, precision_scores_aft):
    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01, f'{precision:.4f}', ha='center', va='bottom')

plt.legend()
plt.show()

import matplotlib.pyplot as plt
from sklearn.metrics import recall_score

# Assuming you have the predictions before and after SMOTE
# Replace these with your actual prediction variables
# Before SMOTE
dt_pred_bfr = dt_classifier_bfr.predict(X_test)  # Decision Tree
rf_pred_bfr = rf_classifier_bfr.predict(X_test)  # Random Forest
svc_pred_bfr = svc_classifier_bfr.predict(X_test)  # SVM
lr_pred_bfr = lr_classifier_bfr.predict(X_test)  # Logistic Regression
knn_pred_bfr = knn_classifier_bfr.predict(X_test)  # KNN
nb_pred_bfr = nb_classifier_bfr.predict(X_test_dense)  # Naive Bayes

# After SMOTE
dt_pred_aft = dt_classifier.predict(X_test)  # Decision Tree
rf_pred_aft = rf_classifier.predict(X_test)  # Random Forest
svc_pred_aft = svc_classifier.predict(X_test)  # SVM
lr_pred_aft = lr_classifier.predict(X_test)  # Logistic Regression
knn_pred_aft = knn_classifier.predict(X_test)  # KNN
nb_pred_aft = nb_classifier.predict(X_test_dense)  # Naive Bayes

# Calculate recall for each classifier before SMOTE
recall_dt_bfr = recall_score(y_test, dt_pred_bfr, average='weighted')
recall_rf_bfr = recall_score(y_test, rf_pred_bfr, average='weighted')
recall_svc_bfr = recall_score(y_test, svc_pred_bfr, average='weighted')
recall_lr_bfr = recall_score(y_test, lr_pred_bfr, average='weighted')
recall_knn_bfr = recall_score(y_test, knn_pred_bfr, average='weighted')
recall_nb_bfr = recall_score(y_test, nb_pred_bfr, average='weighted')

# Calculate recall for each classifier after SMOTE
recall_dt_aft = recall_score(y_test, dt_pred_aft, average='weighted')
recall_rf_aft = recall_score(y_test, rf_pred_aft, average='weighted')
recall_svc_aft = recall_score(y_test, svc_pred_aft, average='weighted')
recall_lr_aft = recall_score(y_test, lr_pred_aft, average='weighted')
recall_knn_aft = recall_score(y_test, knn_pred_aft, average='weighted')
recall_nb_aft = recall_score(y_test, nb_pred_aft, average='weighted')

# Recall scores before and after using SMOTE
recall_scores_bfr = [recall_dt_bfr, recall_rf_bfr, recall_svc_bfr, recall_lr_bfr, recall_knn_bfr, recall_nb_bfr]
recall_scores_aft = [recall_dt_aft, recall_rf_aft, recall_svc_aft, recall_lr_aft, recall_knn_aft, recall_nb_aft]
models = ['Pohon Keputusan', 'Hutan Rawak', 'Mesin Vektor Sokongan', 'Regresi Logistik', 'K-Jiran Terdekat', 'Bayes Naif']

# Plot
plt.figure(figsize=(14, 10))
bar_width = 0.35
index = range(len(models))

# Bars for recall scores before SMOTE
bars1 = plt.bar(index, recall_scores_bfr, bar_width, color='salmon', label='Sebelum SMOTE')

# Bars for recall scores after SMOTE
bars2 = plt.bar([i + bar_width for i in index], recall_scores_aft, bar_width, color='lightgreen', label='Selepas SMOTE')

plt.xlabel('Model')
plt.ylabel('Dapatan Semula')
plt.title('Perbandingan dapatan semula antara model')
plt.ylim(0, 1)
plt.xticks([i + bar_width / 2 for i in index], models, rotation=45)

# Add annotations for before SMOTE
for bar, recall in zip(bars1, recall_scores_bfr):
    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01, f'{recall:.4f}', ha='center', va='bottom')

# Add annotations for after SMote
for bar, recall in zip(bars2, recall_scores_aft):
    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01, f'{recall:.4f}', ha='center', va='bottom')

plt.legend()
plt.show()

import matplotlib.pyplot as plt
from sklearn.metrics import f1_score

# Assuming you have the predictions before and after SMOTE
# Replace these with your actual prediction variables
# Before SMOTE
dt_pred_bfr = dt_classifier_bfr.predict(X_test)  # Decision Tree
rf_pred_bfr = rf_classifier_bfr.predict(X_test)  # Random Forest
svc_pred_bfr = svc_classifier_bfr.predict(X_test)  # SVM
lr_pred_bfr = lr_classifier_bfr.predict(X_test)  # Logistic Regression
knn_pred_bfr = knn_classifier_bfr.predict(X_test)  # KNN
nb_pred_bfr = nb_classifier_bfr.predict(X_test_dense)  # Naive Bayes

# After SMOTE
dt_pred_aft = dt_classifier.predict(X_test)  # Decision Tree
rf_pred_aft = rf_classifier.predict(X_test)  # Random Forest
svc_pred_aft = svc_classifier.predict(X_test)  # SVM
lr_pred_aft = lr_classifier.predict(X_test)  # Logistic Regression
knn_pred_aft = knn_classifier.predict(X_test)  # KNN
nb_pred_aft = nb_classifier.predict(X_test_dense)  # Naive Bayes

# Calculate F1-score for each classifier before SMOTE
f1_dt_bfr = f1_score(y_test, dt_pred_bfr, average='weighted')
f1_rf_bfr = f1_score(y_test, rf_pred_bfr, average='weighted')
f1_svc_bfr = f1_score(y_test, svc_pred_bfr, average='weighted')
f1_lr_bfr = f1_score(y_test, lr_pred_bfr, average='weighted')
f1_knn_bfr = f1_score(y_test, knn_pred_bfr, average='weighted')
f1_nb_bfr = f1_score(y_test, nb_pred_bfr, average='weighted')

# Calculate F1-score for each classifier after SMOTE
f1_dt_aft = f1_score(y_test, dt_pred_aft, average='weighted')
f1_rf_aft = f1_score(y_test, rf_pred_aft, average='weighted')
f1_svc_aft = f1_score(y_test, svc_pred_aft, average='weighted')
f1_lr_aft = f1_score(y_test, lr_pred_aft, average='weighted')
f1_knn_aft = f1_score(y_test, knn_pred_aft, average='weighted')
f1_nb_aft = f1_score(y_test, nb_pred_aft, average='weighted')

# F1-scores before and after using SMOTE
f1_scores_bfr = [f1_dt_bfr, f1_rf_bfr, f1_svc_bfr, f1_lr_bfr, f1_knn_bfr, f1_nb_bfr]
f1_scores_aft = [f1_dt_aft, f1_rf_aft, f1_svc_aft, f1_lr_aft, f1_knn_aft, f1_nb_aft]
models = ['Pohon Keputusan', 'Hutan Rawak', 'Mesin Vektor Sokongan', 'Regresi Logistik', 'K-Jiran Terdekat', 'Bayes Naif']

# Plot
plt.figure(figsize=(14, 10))
bar_width = 0.35
index = range(len(models))

# Bars for F1-scores before SMOTE
bars1 = plt.bar(index, f1_scores_bfr, bar_width, color='salmon', label='Sebelum SMOTE')

# Bars for F1-scores after SMOTE
bars2 = plt.bar([i + bar_width for i in index], f1_scores_aft, bar_width, color='lightgreen', label='Selepas SMOTE')

plt.xlabel('Model')
plt.ylabel('F1-skor')
plt.title('Perbandingan F1-skor antara model')
plt.ylim(0, 1)
plt.xticks([i + bar_width / 2 for i in index], models, rotation=45)

# Add annotations for before SMOTE
for bar, f1 in zip(bars1, f1_scores_bfr):
    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01, f'{f1:.4f}', ha='center', va='bottom')

# Add annotations for after SMOTE
for bar, f1 in zip(bars2, f1_scores_aft):
    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01, f'{f1:.4f}', ha='center', va='bottom')

plt.legend()
plt.show()

"""# MODEL PKL"""

from sklearn.ensemble import RandomForestClassifier
from joblib import dump

# Model Training
random_forest_classifier = RandomForestClassifier()
random_forest_classifier.fit(X_train_smote, y_train_smote)

# Saving the model and the vectorizer
dump(random_forest_classifier, 'random_forest_model.pkl')
dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')

from joblib import load

# Load the pre-trained Random Forest model and count vectorizer
model = load('random_forest_model.pkl')
tfidf_vectorizer = load('tfidf_vectorizer.pkl')

from sklearn.svm import SVC
from joblib import dump

# Model Training
svc_classifier = SVC()
svc_classifier.fit(X_train, y_train)

# Saving the model and vectorizer
dump(svc_classifier, 'svc_model.pkl')
dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')

from joblib import load

# Load the pre-trained model and count vectorizer
model = load('svc_model.pkl')
tfidf_vectorizer = load('tfidf_vectorizer.pkl')

"""# STREAMLIT INTERFACE"""

pip install nltk

# Install vaderSentiment and cleantext
!pip install vaderSentiment
!pip install cleantext
!pip install streamlit -q
!pip install streamlit-option-menu

# Commented out IPython magic to ensure Python compatibility.
# %%writefile sephora.py

!wget -q -O - ipv4.icanhazip.com

!streamlit run sephora.py & npx localtunnel --port 8501

import streamlit as st
import pandas as pd
import altair as alt
import base64
import nltk
import cleantext
import re
from sklearn.svm import SVC
from joblib import load
from textblob import TextBlob
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from streamlit_option_menu import option_menu
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords
from PIL import Image

# Download NLTK resources
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('stopwords')

# Load image for page icon
img = Image.open('sephora.png')
st.set_page_config(page_title='Sentiment Analysis', page_icon=img)

# Load the pre-trained Random Forest model and count vectorizer
model = load('random_forest_model.pkl')
tfidf_vectorizer = load('tfidf_vectorizer.pkl')

# Function to clean and lemmatize text
def clean_and_lemmatize_text(text):
    # Remove emojis
    text = re.sub(r'[^\w\s,]', '', text)

    # Remove digits and non-word/space characters
    text = re.sub(r'\d+', '', text)
    text = re.sub(r'[^a-zA-Z\s]', '', text)

    # Remove consecutive repeating characters
    text = re.sub(r'(.)\1+', r'\1\1', text)

    # Clean the text using cleantext
    cleaned_text = cleantext.clean(
        text,
        clean_all=False,
        extra_spaces=True,
        stopwords=True,
        lowercase=True,
        numbers=True,
        punct=True
    )
    lemmatizer = WordNetLemmatizer()
    tokens = word_tokenize(cleaned_text)  # Tokenize the cleaned text
    stop_words = set(stopwords.words('english'))

    # Lemmatize each word and join them back into a sentence
    lemmatized_tokens = []
    for token in tokens:
        if token.endswith('ing'):
            # Example: running -> run
            lemma = lemmatizer.lemmatize(token, pos='v')
        elif token.endswith('ed'):
            # Example: walked -> walk
            lemma = lemmatizer.lemmatize(token, pos='v')
        else:
            lemma = lemmatizer.lemmatize(token)
        if lemma not in stop_words:
            lemmatized_tokens.append(lemma)
    return ' '.join(lemmatized_tokens)

# Function to analyze sentiment of individual tokens in text
def analyze_token_sentiment(docx):
    analyzer = SentimentIntensityAnalyzer()
    pos_list = []
    neg_list = []
    neu_list = []
    for i in docx.split():
        res = analyzer.polarity_scores(i)['compound']
        if res > 0.1:
            pos_list.append(i)
            pos_list.append(res)
        elif res <= -0.1:
            neg_list.append(i)
            neg_list.append(res)
        else:
            neu_list.append(i)
    result = {'positives': pos_list, 'negatives': neg_list, 'neutral': neu_list}
    return result

# Function to convert sentiment analysis result to DataFrame
def convert_to_df(sentiment):
    sentiment_dict = {'polarity': sentiment.polarity, 'subjectivity': sentiment.subjectivity}
    sentiment_df = pd.DataFrame(sentiment_dict.items(), columns=['metric', 'value'])
    return sentiment_df

# Main function
def main():
    selected = option_menu(
        menu_title=None,
        options=["Home", "Product Reviews", "Product Recommendation"],
        icons=["house", "book", "heart"],
        menu_icon="cast",
        default_index=0,
        orientation="horizontal",
        styles={
            "container": {"padding": "0!important", "background-color": "white"},
            "icon": {"color": "orange", "font-size": "12px"},
            "nav-link": {"font-size": "12px", "text-align": "left", "margin": "0px", "--hover-color": "#eee"},
            "nav-link-selected": {"background-color": "chocolate"},
        },
    )

    if selected == "Home":
        # Set background image
        page_bg_img = """
        <style>
        [data-testid="stAppViewContainer"] {
          background-image: url("https://images.preview.ph/preview/images/2021/12/22/preview-beauty-awards-skincare-nm.jpg");
          background-size: cover;
        }

        [data-testid = "stHeader"] {
          background-color: rgba(0, 0, 0, 0);
        }
        </style>
        """
        st.markdown(page_bg_img, unsafe_allow_html=True)
        st.markdown("<h1 style='text-align: center; color: blacks;'>Sentiment Analysis Beauty and Skincare Product Review</h1>", unsafe_allow_html=True)

    elif selected == "Product Reviews":
        page_bg_img = """
        <style>
        [data-testid="stAppViewContainer"] {
            background-color: #EED8AE;
        }

        [data-testid = "stHeader"] {
          background-color: rgba(0, 0, 0, 0);
        }
        </style>
        """
        st.markdown(page_bg_img, unsafe_allow_html=True)

        with st.form(key='nlpForm'):
            raw_text = st.text_input("**Enter Product Name:**")
            raw_text = st.text_area("**Enter Product Review:**")
            #submit_button = st.form_submit_button(label='**Analyze**')

            pre = st.text_input("**Original Text:**")
            if pre:
                # Clean and lemmatize the text
                lemmatized_text = clean_and_lemmatize_text(pre)
                st.write("**Cleaned Text:**", lemmatized_text)
            submit_button = st.form_submit_button(label='**Analyze**')

        col1, col2 = st.columns(2)
        if submit_button:
            if not raw_text:
                st.warning("**Please enter product review to analyze!**:warning:")
            else:
                with col1:
                    st.info("**Results**")
                    sentiment = TextBlob(raw_text).sentiment
                    st.write(sentiment)

                    if sentiment.polarity > 0.05:
                        st.markdown("**Sentiment: Positive :smiley:** ")
                    elif sentiment.polarity < -0.05:
                        st.markdown("**Sentiment: Negative :angry:** ")
                    else:
                        st.markdown("**Sentiment: Neutral 😐** ")

                    result_df = convert_to_df(sentiment)
                    st.dataframe(result_df)

                    c = alt.Chart(result_df).mark_bar().encode(
                        x='metric',
                        y='value',
                        color='metric')
                    st.altair_chart(c, use_container_width=True)

                with col2:
                    st.info("**Token Sentiment**")
                    token_sentiment = analyze_token_sentiment(raw_text)
                    st.write(token_sentiment)

        with st.expander('**Analyze CSV**'):
            upl = st.file_uploader('Upload file')

            def score(x):
                if isinstance(x, str):
                    blob1 = TextBlob(x)
                    return blob1.sentiment.polarity
                else:
                    return 0

            def analyze(x):
                if x > 0.05:
                    return 'Positive'
                elif x < -0.05:
                    return 'Negative'
                else:
                    return 'Neutral'

            if upl:
                df = pd.read_csv(upl)
                df['Score'] = df['review_text'].apply(score)
                df['analysis'] = df['Score'].apply(analyze)
                st.write(df.head())

                @st.cache_data
                def convert_df(df):
                    return df.to_csv().encode('utf-8')

                csv = convert_df(df)

                st.download_button(
                    label="Download data as CSV",
                    data=csv,
                    file_name='sentiment.csv',
                    mime='text/csv',
                )

    elif selected == "Product Recommendation":
        page_bg_img = """
        <style>
        [data-testid="stAppViewContainer"] {
            background-color: #EED8AE;
        }

        [data-testid = "stHeader"] {
          background-color: rgba(0, 0, 0, 0);
        }
        </style>
        """
        st.markdown(page_bg_img, unsafe_allow_html=True)

        # Automatically read and display data from the uploaded CSV file in Colab environment
        csv_path = 'top_10_brands_sentiment_summary.csv'
        df = pd.read_csv(csv_path)

        st.write("**Top10 recommended product:**")
        st.write(df.head(11))

if __name__ == '__main__':
    main()

import streamlit as st
import pandas as pd
import altair as alt
import base64
import nltk
import cleantext
import re
from sklearn.svm import SVC
from joblib import load
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from streamlit_option_menu import option_menu
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords
from PIL import Image

# Download NLTK resources
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('stopwords')
nltk.download('vader_lexicon')

# Initialize the VADER sentiment analyzer
sid = SentimentIntensityAnalyzer()

# Load image for page icon
img = Image.open('sephora.png')
st.set_page_config(page_title='Sentiment Analysis', page_icon=img)

# Load the pre-trained Random Forest model and count vectorizer
model = load('svc_model.pkl')
tfidf_vectorizer = load('tfidf_vectorizer.pkl')

# Function to clean and lemmatize text
def clean_and_lemmatize_text(text):
    # Remove emojis
    text = re.sub(r'[^\w\s,]', '', text)

    # Remove digits and non-word/space characters
    text = re.sub(r'\d+', '', text)
    text = re.sub(r'[^a-zA-Z\s]', '', text)

    # Remove consecutive repeating characters
    text = re.sub(r'(.)\1+', r'\1\1', text)

    # Clean the text using cleantext
    cleaned_text = cleantext.clean(
        text,
        clean_all=False,
        extra_spaces=True,
        stopwords=True,
        lowercase=True,
        numbers=True,
        punct=True
    )
    lemmatizer = WordNetLemmatizer()
    tokens = word_tokenize(cleaned_text)  # Tokenize the cleaned text
    stop_words = set(stopwords.words('english'))

    # Lemmatize each word and join them back into a sentence
    lemmatized_tokens = []
    for token in tokens:
        if token.endswith('ing'):
            # Example: running -> run
            lemma = lemmatizer.lemmatize(token, pos='v')
        elif token.endswith('ed'):
            # Example: walked -> walk
            lemma = lemmatizer.lemmatize(token, pos='v')
        else:
            lemma = lemmatizer.lemmatize(token)
        if lemma not in stop_words:
            lemmatized_tokens.append(lemma)
    return ' '.join(lemmatized_tokens)

# Function to analyze sentiment of individual tokens in text
def analyze_token_sentiment(docx):
    analyzer = SentimentIntensityAnalyzer()
    pos_list = []
    neg_list = []
    neu_list = []
    for i in docx.split():
        res = analyzer.polarity_scores(i)['compound']
        if res > 0.05:
            pos_list.append(i)
            pos_list.append(res)
        elif res <= -0.05:
            neg_list.append(i)
            neg_list.append(res)
        else:
            neu_list.append(i)
    result = {'positives': pos_list, 'negatives': neg_list, 'neutral': neu_list}
    return result

# Function to convert sentiment analysis result to DataFrame
def convert_to_df(sentiment):
    sentiment_dict = {'polarity': sentiment.polarity, 'subjectivity': sentiment.subjectivity}
    sentiment_df = pd.DataFrame(sentiment_dict.items(), columns=['metric', 'value'])
    return sentiment_df

# Main function
def main():
    selected = option_menu(
        menu_title=None,
        options=["Home", "Product Review Analyzer", "Product Recommendation"],
        icons=["house", "book", "heart"],
        menu_icon="cast",
        default_index=0,
        orientation="horizontal",
        styles={
            "container": {"padding": "0!important", "background-color": "white"},
            "icon": {"color": "orange", "font-size": "12px"},
            "nav-link": {"font-size": "12px", "text-align": "left", "margin": "0px", "--hover-color": "#eee"},
            "nav-link-selected": {"background-color": "chocolate"},
        },
    )

    if selected == "Home":
        # Set background image
        page_bg_img = """
        <style>
        [data-testid="stAppViewContainer"] {
          background-image: url("https://images.preview.ph/preview/images/2021/12/22/preview-beauty-awards-skincare-nm.jpg ");
          background-size: cover;
        }

        [data-testid = "stHeader"] {
          background-color: rgba(0, 0, 0, 0);
        }
        </style>
        """

        st.markdown(page_bg_img, unsafe_allow_html=True)
        st.markdown("<h1 style='text-align: center; color: blacks;'>Sentiment Analysis Beauty and Skincare Product Review</h1>", unsafe_allow_html=True)
        st.write("""
        This project aims to conduct sentiment analysis on beauty and skincare product reviews sourced from Sephora.com.
        The objective is to classify reviews as positive, negative or neutral.

        By categorizing the reviews, the analysis aims to provide insights into customer satisfaction and preferences, helping brands understand consumer opinions and can improve their products.
        This sentiment analysis can also guide potential buyers by highlighting the general sentiment towards various products, thus influencing purchasing decisions.

        Let's delve into the review analysis!!!
        """)

    elif selected == "Product Review Analyzer":
        page_bg_img = """
        <style>
        [data-testid="stAppViewContainer"] {
            background-color: #EED8AE;
        }

        [data-testid = "stHeader"] {
          background-color: rgba(0, 0, 0, 0);
        }
        </style>
        """
        st.markdown(page_bg_img, unsafe_allow_html=True)

        with st.form(key='nlpForm'):
            raw_text = st.text_input("**Enter Product Name:**")
            raw_text = st.text_area("**Enter Product Review:**")

            pre = st.text_area("**Original Text:**")
            if pre:
                # Clean and lemmatize the text
                lemmatized_text = clean_and_lemmatize_text(pre)
                st.write("**Cleaned Text:**", lemmatized_text)
            submit_button = st.form_submit_button(label='**Analyze**')

        if submit_button:
            if not raw_text:
                st.warning("**Please enter product review to analyze!**:warning:")
            else:
                st.info("**Results**")

                # Ensure proper encoding before analysis
                raw_text = raw_text.encode('utf-8').decode('utf-8', 'ignore')

                # Use VADER to compute sentiment scores
                scores = sid.polarity_scores(raw_text)
                compound_score = scores['compound']

                # Display the sentiment label with larger font size
                if compound_score > 0.05:
                    st.markdown("<h3 style='font-size: 20px; color: green;'>Sentiment: Positive 😊</h3>", unsafe_allow_html=True)
                elif compound_score < -0.05:
                    st.markdown("<h3 style='font-size: 20px; color: red;'>Sentiment: Negative 😡</h3>", unsafe_allow_html=True)
                else:
                    st.markdown("<h3 style='font-size: 20px; color: yellow;'>Sentiment: Neutral 😐</h3>", unsafe_allow_html=True)

                # Create a DataFrame from the sentiment analysis
                sentiment = pd.DataFrame([{
                    'metric': 'compound',
                    'value': compound_score
                }])

                # Create and display a bar chart
                c = alt.Chart(sentiment).mark_bar().encode(
                    x='metric',
                    y='value',
                    color='metric'
                )

                # Create columns to display the DataFrame and the chart side by side
                col1, col2 = st.columns(2)
                with col1:
                    st.dataframe(sentiment)
                with col2:
                    st.altair_chart(c, use_container_width=True)

        with st.expander('**Analyze CSV**'):
            upl = st.file_uploader('Upload file')

            def score(x):
                if isinstance(x, str):
                    scores = sid.polarity_scores(x)
                    return scores['compound']
                else:
                    return 0

            def analyze(x):
                if x > 0.05:
                    return 'Positive'
                elif x < -0.05:
                    return 'Negative'
                else:
                    return 'Neutral'

            if upl:
                df = pd.read_csv(upl)
                df['Score'] = df['review_text'].apply(score)
                df['analysis'] = df['Score'].apply(analyze)
                st.write(df.head())

                @st.cache_data
                def convert_df(df):
                    return df.to_csv().encode('utf-8')

                csv = convert_df(df)

                st.download_button(
                    label="Download data as CSV",
                    data=csv,
                    file_name='sentiment.csv',
                    mime='text/csv',
                )

    elif selected == "Product Recommendation":
        page_bg_img = """
        <style>
        [data-testid="stAppViewContainer"] {
            background-color: #EED8AE;
        }

        [data-testid = "stHeader"] {
          background-color: rgba(0, 0, 0, 0);
        }
        </style>
        """
        st.markdown(page_bg_img, unsafe_allow_html=True)

        # Automatically read and display data from the uploaded CSV file in Colab environment
        csv_path = 'top_10_brands_sentiment_summary.csv'
        df = pd.read_csv(csv_path)

        st.write("**Top10 recommended product:**")
        st.write(df.head(11))

if __name__ == '__main__':
    main()

import streamlit as st
import pandas as pd
import altair as alt
import base64
import nltk
import cleantext
import re
from sklearn.svm import SVC
from joblib import load
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from streamlit_option_menu import option_menu
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords
from PIL import Image

# Download NLTK resources
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('stopwords')
nltk.download('vader_lexicon')

# Initialize the VADER sentiment analyzer
sid = SentimentIntensityAnalyzer()

# Load image for page icon
img = Image.open('sephora.png')
st.set_page_config(page_title='Sentiment Analysis', page_icon=img)

# Load the pre-trained Random Forest model and count vectorizer
model = load('svc_model.pkl')
tfidf_vectorizer = load('tfidf_vectorizer.pkl')

# Function to clean and lemmatize text
def clean_and_lemmatize_text(text):
    # Remove emojis
    text = re.sub(r'[^\w\s,]', '', text)

    # Remove digits and non-word/space characters
    text = re.sub(r'\d+', '', text)
    text = re.sub(r'[^a-zA-Z\s]', '', text)

    # Remove consecutive repeating characters
    text = re.sub(r'(.)\1+', r'\1\1', text)

    # Clean the text using cleantext
    cleaned_text = cleantext.clean(
        text,
        clean_all=False,
        extra_spaces=True,
        stopwords=True,
        lowercase=True,
        numbers=True,
        punct=True
    )
    lemmatizer = WordNetLemmatizer()
    tokens = word_tokenize(cleaned_text)  # Tokenize the cleaned text
    stop_words = set(stopwords.words('english'))

    # Lemmatize each word and join them back into a sentence
    lemmatized_tokens = []
    for token in tokens:
        if token.endswith('ing'):
            # Example: running -> run
            lemma = lemmatizer.lemmatize(token, pos='v')
        elif token.endswith('ed'):
            # Example: walked -> walk
            lemma = lemmatizer.lemmatize(token, pos='v')
        else:
            lemma = lemmatizer.lemmatize(token)
        if lemma not in stop_words:
            lemmatized_tokens.append(lemma)
    return ' '.join(lemmatized_tokens)

# Function to analyze sentiment of individual tokens in text
def analyze_token_sentiment(docx):
    analyzer = SentimentIntensityAnalyzer()
    pos_list = []
    neg_list = []
    neu_list = []
    for i in docx.split():
        res = analyzer.polarity_scores(i)['compound']
        if res > 0.05:
            pos_list.append(i)
            pos_list.append(res)
        elif res <= -0.05:
            neg_list.append(i)
            neg_list.append(res)
        else:
            neu_list.append(i)
    result = {'positives': pos_list, 'negatives': neg_list, 'neutral': neu_list}
    return result

# Function to convert sentiment analysis result to DataFrame
def convert_to_df(sentiment):
    sentiment_dict = {'polarity': sentiment.polarity, 'subjectivity': sentiment.subjectivity}
    sentiment_df = pd.DataFrame(sentiment_dict.items(), columns=['metric', 'value'])
    return sentiment_df

# Main function
def main():
    selected = option_menu(
        menu_title=None,
        options=["Home", "Product Review Analyzer", "Product Recommendation"],
        icons=["house", "book", "heart"],
        menu_icon="cast",
        default_index=0,
        orientation="horizontal",
        styles={
            "container": {"padding": "0!important", "background-color": "white"},
            "icon": {"color": "orange", "font-size": "12px"},
            "nav-link": {"font-size": "12px", "text-align": "left", "margin": "0px", "--hover-color": "#eee"},
            "nav-link-selected": {"background-color": "chocolate"},
        },
    )

    if selected == "Home":
        # Set background image
        page_bg_img = """
        <style>
        [data-testid="stAppViewContainer"] {
          background-image: url("https://images.preview.ph/preview/images/2021/12/22/preview-beauty-awards-skincare-nm.jpg ");
          background-size: cover;
        }

        [data-testid = "stHeader"] {
          background-color: rgba(0, 0, 0, 0);
        }
        </style>
        """

        st.markdown(page_bg_img, unsafe_allow_html=True)
        st.markdown("<h1 style='text-align: center; color: blacks;'>Sentiment Analysis Beauty and Skincare Product Review</h1>", unsafe_allow_html=True)
        st.write("""
        This project aims to conduct sentiment analysis on beauty and skincare product reviews sourced from Sephora.com.
        The objective is to classify reviews as positive, negative or neutral.

        By categorizing the reviews, the analysis aims to provide insights into customer satisfaction and preferences, helping brands understand consumer opinions and can improve their products.
        This sentiment analysis can also guide potential buyers by highlighting the general sentiment towards various products, thus influencing purchasing decisions.

        Let's delve into the review analysis!!!
        """)

    elif selected == "Product Review Analyzer":
        page_bg_img = """
        <style>
        [data-testid="stAppViewContainer"] {
            background-color: #EED8AE;
        }

        [data-testid = "stHeader"] {
          background-color: rgba(0, 0, 0, 0);
        }
        </style>
        """
        st.markdown(page_bg_img, unsafe_allow_html=True)

        with st.form(key='nlpForm'):
            product_name = st.text_input("**Enter Product Name:**")
            product_review = st.text_area("**Enter Product Review:**")

            original_text = st.text_area("**Original Text:**")
            if original_text:
                # Clean and lemmatize the text
                lemmatized_text = clean_and_lemmatize_text(original_text)
                st.write("**Cleaned Text:**", lemmatized_text)

            submit_button = st.form_submit_button(label='**Analyze**')

        if submit_button:
            word_count = len(product_review.split())
            if word_count > 300:
                st.warning("**Product review exceeds 300 words. Please shorten your review.** :warning:")
            elif not product_review:
                st.warning("**Please enter product review to analyze!**:warning:")
            else:
                st.info("**Results**")

                # Ensure proper encoding before analysis
                product_review = product_review.encode('utf-8').decode('utf-8', 'ignore')

                # Use VADER to compute sentiment scores
                scores = sid.polarity_scores(product_review)
                compound_score = scores['compound']

                # Display the sentiment label with larger font size
                if compound_score > 0.05:
                    st.markdown("<h3 style='font-size: 20px; color: green;'>Sentiment: Positive 😊</h3>", unsafe_allow_html=True)
                elif compound_score < -0.05:
                    st.markdown("<h3 style='font-size: 20px; color: red;'>Sentiment: Negative 😡</h3>", unsafe_allow_html=True)
                else:
                    st.markdown("<h3 style='font-size: 20px; color: yellow;'>Sentiment: Neutral 😐</h3>", unsafe_allow_html=True)

                # Create a DataFrame from the sentiment analysis
                sentiment = pd.DataFrame([{
                    'metric': 'compound',
                    'value': compound_score
                }])

                # Create and display a bar chart
                c = alt.Chart(sentiment).mark_bar().encode(
                    x='metric',
                    y='value',
                    color='metric'
                )

                # Create columns to display the DataFrame and the chart side by side
                col1, col2 = st.columns(2)
                with col1:
                    st.dataframe(sentiment)
                with col2:
                    st.altair_chart(c, use_container_width=True)

        with st.expander('**Analyze CSV**'):
            upl = st.file_uploader('Upload file')

            def score(x):
                if isinstance(x, str):
                    scores = sid.polarity_scores(x)
                    return scores['compound']
                else:
                    return 0

            def analyze(x):
                if x > 0.05:
                    return 'Positive'
                elif x < -0.05:
                    return 'Negative'
                else:
                    return 'Neutral'

            if upl:
                df = pd.read_csv(upl)
                df['Score'] = df['review_text'].apply(score)
                df['analysis'] = df['Score'].apply(analyze)
                st.write(df.head())

                @st.cache_data
                def convert_df(df):
                    return df.to_csv().encode('utf-8')

                csv = convert_df(df)

                st.download_button(
                    label="Download data as CSV",
                    data=csv,
                    file_name='sentiment.csv',
                    mime='text/csv',
                )

    elif selected == "Product Recommendation":
        page_bg_img = """
        <style>
        [data-testid="stAppViewContainer"] {
            background-color: #EED8AE;
        }

        [data-testid = "stHeader"] {
          background-color: rgba(0, 0, 0, 0);
        }
        </style>
        """
        st.markdown(page_bg_img, unsafe_allow_html=True)

        # Automatically read and display data from the uploaded CSV file in Colab environment
        csv_path = 'top_10_brands_sentiment_summary.csv'
        df = pd.read_csv(csv_path)

        st.write("**Top10 recommended product:**")
        st.write(df.head(11))

if __name__ == '__main__':
    main()

"""Positive
1. this oil helped with hydration and breakouts, I love this!!
2. Excellent product, my skin is softer. Lightweight product and the smell is amazing. Highly recommended!
3. Great product, I apply in the morning and my skin stays hydrated for the whole day. I donâ€™t Get oily skin after applying and thatâ€™s a huge win for me.
4. I love this acne wash! I don;t  use any other one and need to order another soon!! I def recommend this product!


Negative
1. Works instantaneously and lasts all day long. I couldnâ€™t have survived this brutal winter without it.
2. Awful!!!! Stinks, sticky and goes bad (oxidation) fast. Worst thing Iâ€™ve ever purchased from Sephora
3. i was really wanting to love this but unfortunately it broke me out. i would suggest the drunk elephant or tatcha c serums.
4. Horrible packaging - leaked everywhere and I lost a majority of this expensive product that way. Also pretty greasy. But I guess it does work which is why Iâ€™m leaving 2 stars. Pretty disappointed with this purchase.

Neutral
1. On 3rd bottle. Its the food for my skin, at time i only apply this oil massage 2-3 minutes and head out. Its very lite, glowing yet non greasy. Takes my foundation to next level.
2. makes skin look healthier with daily use
3. Was so excited to try this out on my face and body, because it is SPF 50 when most are just 30. Sadly the alcohol dried out my skin, causing me to break out.
4. Used once but just couldnâ€™t take the smell. Returned 1st tube but 2nd tube smells the same. Moving on.



"""